# Huggingface KoBERT
## data https://github.com/e9t/nsmc
## ref. https://huggingface.co/docs/transformers/tasks/sequence_classification

## 결론
### 허깅페이스를 활용해서 네이버 영화리뷰를 진행해봤습니다.
### 허깅페이스 자체가 워낙 잘 만들어논 프레임워크라 사용에도 전혀 어려움이 없었고 결과도 뭐 나쁘지 않았구요
### 다만 오씨가 처음에 테스크를 잘못줘서 이게 뭐하라는거지???????? 했던 부분만 빼면.............ㅋ
### 단순 fine-tuning하고 다이나믹 패딩을 활용한 모델의 비교를 해보자면
### 우선 단순 판단했던거와 다르게 다이나믹 패딩을 활용했던 모델이 더 정확도와 로스가 더 좋게 나왔습니다. 애초에 생각했던건 속도를 위해서 다이나믹 패딩을 쳐주고 그다음 후처리를 해주는 개념으로 이해했어 가지구 오히려 시간도 오래 걸리고 정확도도 더 높게 나와서 놀랐습니다.
### 다이나믹 패딩의 전제가 비슷한 길이의 문장들은 비슷한 수준의 표현력을 가지고 있다면, 이를 묶어서 처리하는 것이 학습단계에서 더 유리하다 라는 컨셉이였던거 같습니다.
### 그래서 fine-tunning했을때 죽어도 안넘던 정확도 90이 조금이나마 넘기 시작..ㅎ
### 발상자체의 타당성이나 정합성보다는 결과적으로 나오는 데이터가 더 중요한 분야이기에...인과관계는 여전히 설명이 안되지만 모 그냥 넘어가는걸루

