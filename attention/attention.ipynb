{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380b9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import re\n",
    "import konlpy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78aa798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_train_data = []\n",
    "english_train_data = []\n",
    "korean_test_data = []\n",
    "english_test_data = []\n",
    "\n",
    "with open(\"./korean-english-park.train.ko\", \"r\") as f:\n",
    "    korean_train_data = f.read().splitlines()\n",
    "\n",
    "with open(\"./korean-english-park.train.en\", \"r\") as f:\n",
    "    english_train_data = f.read().splitlines()\n",
    "    \n",
    "with open(\"./korean-english-park.test.ko\", \"r\") as f:\n",
    "    korean_test_data = f.read().splitlines()\n",
    "    \n",
    "with open(\"./korean-english-park.test.en\", \"r\") as f:\n",
    "    english_test_data = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "82eff755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>korean</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>토론에 참여한 사람들은 법 집행과 국가 안전보장에 대한 우려를 표명해야 할 필요성을...</td>\n",
       "      <td>Those involved in the discussions do take seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>또한 새로운 기술 개발이 어떤 해결책을 제공해 주는데 도움이 될 것이고, 동시 에 ...</td>\n",
       "      <td>There is also some hope that new technology de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그래서 클리퍼 칩에 대한 개인적인 해결책은 서서히 자취를 감출 것입니다. 그러나 이...</td>\n",
       "      <td>So the individual solution of the clipper chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이탈리아의 천문학자들이 멀리에 있는 별들의 궤도를 도는 행성의 대기에서 생명체의 필...</td>\n",
       "      <td>Italian astronomers have found signs of water,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>물이 있다는 것이 다른 행성에 생명체들이 가득하다는 것을 의미하지는 않지만, 이번 ...</td>\n",
       "      <td>Having water does not mean other planets will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>코리아 헤럴드는 이번 관련법 개정으로 해외 부동산을 취득하고자 하는 개인에 대한 규...</td>\n",
       "      <td>The Korea Herald reports part of these changes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>또한 투자 펀드를 통해 해외 부동산에 투자하고자 하는 사람들에게도 유리해지도록 법 ...</td>\n",
       "      <td>Other legal changes will help those aiming to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>반 외교부장관, 최근 핵 문제 관련 북한 태도에 경고</td>\n",
       "      <td>Foreign minister Ban warned North Korea for it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>일본, 통근 열차 탈선 사고로 최소 69명 사망</td>\n",
       "      <td>Japan's derailed commuter train accident has k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>중국 공안경찰은 그간 세간의 이목을 끌었던 몇몇 소송을 제기해 온 저명한 인권 운동...</td>\n",
       "      <td>Communist Chinese police have detained a promi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 korean  \\\n",
       "0     토론에 참여한 사람들은 법 집행과 국가 안전보장에 대한 우려를 표명해야 할 필요성을...   \n",
       "1     또한 새로운 기술 개발이 어떤 해결책을 제공해 주는데 도움이 될 것이고, 동시 에 ...   \n",
       "2     그래서 클리퍼 칩에 대한 개인적인 해결책은 서서히 자취를 감출 것입니다. 그러나 이...   \n",
       "3     이탈리아의 천문학자들이 멀리에 있는 별들의 궤도를 도는 행성의 대기에서 생명체의 필...   \n",
       "4     물이 있다는 것이 다른 행성에 생명체들이 가득하다는 것을 의미하지는 않지만, 이번 ...   \n",
       "...                                                 ...   \n",
       "1995  코리아 헤럴드는 이번 관련법 개정으로 해외 부동산을 취득하고자 하는 개인에 대한 규...   \n",
       "1996  또한 투자 펀드를 통해 해외 부동산에 투자하고자 하는 사람들에게도 유리해지도록 법 ...   \n",
       "1997                 반 외교부장관, 최근 핵 문제 관련 북한 태도에 경고        \n",
       "1998                   일본, 통근 열차 탈선 사고로 최소 69명 사망         \n",
       "1999  중국 공안경찰은 그간 세간의 이목을 끌었던 몇몇 소송을 제기해 온 저명한 인권 운동...   \n",
       "\n",
       "                                                english  \n",
       "0     Those involved in the discussions do take seri...  \n",
       "1     There is also some hope that new technology de...  \n",
       "2     So the individual solution of the clipper chip...  \n",
       "3     Italian astronomers have found signs of water,...  \n",
       "4     Having water does not mean other planets will ...  \n",
       "...                                                 ...  \n",
       "1995  The Korea Herald reports part of these changes...  \n",
       "1996  Other legal changes will help those aiming to ...  \n",
       "1997  Foreign minister Ban warned North Korea for it...  \n",
       "1998  Japan's derailed commuter train accident has k...  \n",
       "1999  Communist Chinese police have detained a promi...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame([i for i in zip(korean_train_data, english_train_data)], columns=[\"korean\", \"english\"])\n",
    "test_data = pd.DataFrame([i for i in zip(korean_test_data, english_test_data)], columns=[\"korean\", \"english\"])\n",
    "train_data \n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ded09016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15155\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[train_data.duplicated([\"korean\", \"english\"])]))\n",
    "train_data = train_data.drop_duplicates([\"korean\", \"english\"], ignore_index=True)\n",
    "\n",
    "print(len(test_data[test_data.duplicated([\"korean\", \"english\"])]))\n",
    "test_data = test_data.drop_duplicates([\"korean\", \"english\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a541a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd082144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "korean_corpus = train_data[\"korean\"]\n",
    "english_corpus = train_data[\"english\"]\n",
    "\n",
    "korean_text_corpus = test_data[\"korean\"]\n",
    "english_text_corpus = test_data[\"english\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "341e4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence, korean=True):\n",
    "    sentence = re.sub(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s.,?!\\'\\\"]\", \"\", sentence)\n",
    "    sentence = re.sub(\"\\\"+\", \"\", sentence)\n",
    "    sentence = re.sub(r\"\\.+\", \" .\", sentence)\n",
    "    sentence = re.sub(\"!+\", \" !\", sentence)\n",
    "    sentence = re.sub(\"\\?+\", \" ?\", sentence)\n",
    "    sentence.lower().strip()\n",
    "    if not korean:\n",
    "        sentence = \"<sos> \" + sentence + \" <eos>\"\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6e503bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_corpus = [preprocess(sentence, korean=True) for sentence in korean_corpus]\n",
    "english_corpus = [preprocess(sentence, korean=False) for sentence in english_corpus]\n",
    "\n",
    "korean_text_corpus = [preprocess(sentence, korean=True) for sentence in korean_text_corpus]\n",
    "english_text_corpus = [preprocess(sentence, korean=False) for sentence in english_text_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5c73c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def konlpy_tokenizer(tokenizer, corpus):\n",
    "    words = []\n",
    "    sentences = []\n",
    "    for c in corpus:\n",
    "        temp = tokenizer.morphs(c)\n",
    "        words += temp\n",
    "        sentences.append(temp)\n",
    "        \n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common()\n",
    "    \n",
    "    words = [\"<pad>\", \"<unk>\"] + [key for key, _ in counter]\n",
    "    word_to_index = {word : index for index, word in enumerate(words)}\n",
    "    tensor = []\n",
    "    \n",
    "    for c in sentences:\n",
    "        temp = []\n",
    "        for s in c:\n",
    "            if s in words:\n",
    "                temp.append(word_to_index[s])\n",
    "            else:\n",
    "                temp.append(word_to_index[\"<unk>\"])\n",
    "        tensor.append(temp)\n",
    "    \n",
    "    return tensor, word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "66ab8a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30039\n"
     ]
    }
   ],
   "source": [
    "mecab = konlpy.tag.Mecab()\n",
    "korean_tokens, korean_word_to_index = konlpy_tokenizer(mecab, korean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b884d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_SIZE = len(korean_word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb00cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_text_corpus = [mecab.morphs(k) for k in korean_text_corpus]\n",
    "korean_test = []\n",
    "for c in korean_text_corpus:\n",
    "        temp = []\n",
    "        for s in c:\n",
    "            if s in korean_word_to_index:\n",
    "                temp.append(korean_word_to_index[s])\n",
    "            else:\n",
    "                temp.append(korean_word_to_index[\"<unk>\"])\n",
    "        korean_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4654e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_index_to_word = {word : index for word, index in enumerate(korean_word_to_index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1ae1226f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37531\n",
      "30039\n"
     ]
    }
   ],
   "source": [
    "english_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\" \")\n",
    "english_tokenizer.fit_on_texts(english_corpus)\n",
    "english_tokens = english_tokenizer.texts_to_sequences(english_corpus)\n",
    "english_test = english_tokenizer.texts_to_sequences(english_text_corpus)\n",
    "print(len(english_tokenizer.word_index))\n",
    "print(WORD_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "22ad0fb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder_input = []\n",
    "decoder_input = []\n",
    "\n",
    "for k, e in zip(korean_tokens, english_tokens):\n",
    "    if len(e) < 40 and len(k) < 40:\n",
    "        encoder_input.append(k)\n",
    "        decoder_input.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "17a44c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15451 15451\n"
     ]
    }
   ],
   "source": [
    "print(len(encoder_input), len(decoder_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bf635ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = tf.keras.preprocessing.sequence.pad_sequences(encoder_input, padding='post')\n",
    "decoder_input = tf.keras.preprocessing.sequence.pad_sequences(decoder_input, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4cbd9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_test = []\n",
    "decoder_test = []\n",
    "\n",
    "for k, e in zip(korean_test, english_test):\n",
    "    if len(e) < 40 and len(k) < 40:\n",
    "        encoder_test.append(k)\n",
    "        decoder_test.append(e)\n",
    "\n",
    "encoder_test = tf.keras.preprocessing.sequence.pad_sequences(encoder_test, padding='post')\n",
    "decoder_test = tf.keras.preprocessing.sequence.pad_sequences(decoder_test, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7e951633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "13734189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru1 = tf.keras.layers.GRU(enc_units, return_sequences=True, dropout=0.3)\n",
    "        self.gru2 = tf.keras.layers.GRU(enc_units, return_sequences=True, dropout=0.3)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru1(out)\n",
    "        out = self.gru2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1ebe1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru1 = tf.keras.layers.GRU(dec_units, return_sequences=True, dropout=0.3)\n",
    "        self.gru2 = tf.keras.layers.GRU(dec_units, return_sequences=True, return_state=True, dropout=0.3)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out = self.gru1(out)\n",
    "        out, h_dec = self.gru2(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3e26405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SRC_VOCAB_SIZE = WORD_SIZE + 1\n",
    "TGT_VOCAB_SIZE = len(english_tokenizer.word_index) + 1\n",
    "\n",
    "units = 256\n",
    "embedding_dim = 128\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e54d2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "680a9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index[\"<sos>\"]] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7538a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok.word_index[\"<sos>\"]] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "86b0580f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 1.3896]\n",
      "Epoch  2: 100%|██████████| 61/61 [00:25<00:00,  2.38it/s, Loss 1.3740]\n",
      "Epoch  3: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 1.3598]\n",
      "Epoch  4: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 1.3432]\n",
      "Epoch  5: 100%|██████████| 61/61 [00:25<00:00,  2.43it/s, Loss 1.3323]\n",
      "Epoch  6: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.3211]\n",
      "Epoch  7: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 1.3020]\n",
      "Epoch  8: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.2817]\n",
      "Epoch  9: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.2728]\n",
      "Epoch 10: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.2531]\n",
      "Epoch 11: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.2294]\n",
      "Epoch 12: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.2063]\n",
      "Epoch 13: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.1850]\n",
      "Epoch 14: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 1.1687]\n",
      "Epoch 15: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 1.1568]\n",
      "Epoch 16: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.1497]\n",
      "Epoch 17: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.1458]\n",
      "Epoch 18: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.1292]\n",
      "Epoch 19: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 1.1094]\n",
      "Epoch 20: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.0860]\n",
      "Epoch 21: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.0678]\n",
      "Epoch 22: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.0550]\n",
      "Epoch 23: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.0409]\n",
      "Epoch 24: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.0381]\n",
      "Epoch 25: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.0292]\n",
      "Epoch 26: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 1.0134]\n",
      "Epoch 27: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.9997]\n",
      "Epoch 28: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.9915]\n",
      "Epoch 29: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.9753]\n",
      "Epoch 30: 100%|██████████| 61/61 [00:25<00:00,  2.44it/s, Loss 0.9592]\n",
      "Epoch 31: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.9518]\n",
      "Epoch 32: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.9420]\n",
      "Epoch 33: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.9367]\n",
      "Epoch 34: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.9372]\n",
      "Epoch 35: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.9268]\n",
      "Epoch 36: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.9085]\n",
      "Epoch 37: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.8909]\n",
      "Epoch 38: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.8764]\n",
      "Epoch 39: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.8645]\n",
      "Epoch 40: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.8482]\n",
      "Epoch 41: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.8447]\n",
      "Epoch 42: 100%|██████████| 61/61 [00:25<00:00,  2.44it/s, Loss 0.8333]\n",
      "Epoch 43: 100%|██████████| 61/61 [00:25<00:00,  2.44it/s, Loss 0.8213]\n",
      "Epoch 44: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.8038]\n",
      "Epoch 45: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.7947]\n",
      "Epoch 46: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.7820]\n",
      "Epoch 47: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.7701]\n",
      "Epoch 48: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7544]\n",
      "Epoch 49: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7477]\n",
      "Epoch 50: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7399]\n",
      "Epoch 51: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7373]\n",
      "Epoch 52: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7309]\n",
      "Epoch 53: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7196]\n",
      "Epoch 54: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7077]\n",
      "Epoch 55: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.7012]\n",
      "Epoch 56: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6872]\n",
      "Epoch 57: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6697]\n",
      "Epoch 58: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6649]\n",
      "Epoch 59: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6556]\n",
      "Epoch 60: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6469]\n",
      "Epoch 61: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6441]\n",
      "Epoch 62: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6428]\n",
      "Epoch 63: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6349]\n",
      "Epoch 64: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6327]\n",
      "Epoch 65: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6330]\n",
      "Epoch 66: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.6291]\n",
      "Epoch 67: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 0.6180]\n",
      "Epoch 68: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5987]\n",
      "Epoch 69: 100%|██████████| 61/61 [00:25<00:00,  2.44it/s, Loss 0.5780]\n",
      "Epoch 70: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.5718]\n",
      "Epoch 71: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5790]\n",
      "Epoch 72: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5800]\n",
      "Epoch 73: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5694]\n",
      "Epoch 74: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5543]\n",
      "Epoch 75: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5397]\n",
      "Epoch 76: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5331]\n",
      "Epoch 77: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5219]\n",
      "Epoch 78: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5110]\n",
      "Epoch 79: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.5031]\n",
      "Epoch 80: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 0.4991]\n",
      "Epoch 81: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 0.4915]\n",
      "Epoch 82: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.4884]\n",
      "Epoch 83: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.4881]\n",
      "Epoch 84: 100%|██████████| 61/61 [00:25<00:00,  2.44it/s, Loss 0.4893]\n",
      "Epoch 85: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.4914]\n",
      "Epoch 86: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.4909]\n",
      "Epoch 87: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.4821]\n",
      "Epoch 88: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.4690]\n",
      "Epoch 89: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.4608]\n",
      "Epoch 90: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.4564]\n",
      "Epoch 91: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 0.4476]\n",
      "Epoch 92: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.4354]\n",
      "Epoch 93: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.4250]\n",
      "Epoch 94: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.4164]\n",
      "Epoch 95: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.4129]\n",
      "Epoch 96: 100%|██████████| 61/61 [00:25<00:00,  2.44it/s, Loss 0.4064]\n",
      "Epoch 97: 100%|██████████| 61/61 [00:24<00:00,  2.44it/s, Loss 0.4026]\n",
      "Epoch 98: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.3952]\n",
      "Epoch 99: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s, Loss 0.3924]\n",
      "Epoch 100: 100%|██████████| 61/61 [00:24<00:00,  2.45it/s, Loss 0.3866]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, encoder_input.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)  \n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(encoder_input[idx:idx+BATCH_SIZE],\n",
    "                                decoder_input[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                english_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        loss.append((total_loss.numpy() / (batch + 1)))\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1)) \n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9b53c358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.title(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "061ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sentence):\n",
    "    input_sentence = preprocess(input_sentence)\n",
    "    input_sentence = [korean_word_to_index[s] for s in mecab.morphs(input_sentence)]\n",
    "    input_sentence = tf.keras.preprocessing.sequence.pad_sequences([input_sentence], padding=\"post\", maxlen=39)\n",
    "  \n",
    "    states_value = encoder(input_sentence)\n",
    "    \n",
    "    decoder_hidden = states_value[:, -1]\n",
    "    decoder_input = tf.expand_dims([english_tokenizer.word_index[\"<sos>\"]], 0)\n",
    "    \n",
    "    flag = True\n",
    "    decoded_sentence = \"\"\n",
    "    while flag:\n",
    "        output_tokens, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, states_value)\n",
    "\n",
    "        sampled_token_index = tf.argmax(tf.math.softmax(output_tokens, axis=-1)[0]).numpy()\n",
    "        sampled_token = english_tokenizer.index_word[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"<eos>\" or len(decoded_sentence) > 39:\n",
    "            flag = False\n",
    "        decoder_input = tf.expand_dims([sampled_token_index], 0)\n",
    "\n",
    "    return decoded_sentence[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "32f6c819",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for the next project\n",
      " one is a new trademark dispute .\n",
      " they had no longer the right for the ap\n"
     ]
    }
   ],
   "source": [
    "print(decode_sequence(\"처음부터 시작\"))\n",
    "print(decode_sequence(\"전쟁이 발발하였습니다\"))\n",
    "print(decode_sequence(\"지구온난화가 심각하다고 주장했습니다\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
